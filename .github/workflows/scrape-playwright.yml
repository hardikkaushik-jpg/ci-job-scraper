name: Scrape and Push Jobs (Enterprise C+ Pipeline)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"   # Daily at 06:00 UTC

jobs:
  scrape_and_clean:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install chromium

      - name: Run Enterprise Scraper
        run: |
          python jobs_smart_cplus.py

      - name: Clean & Enrich Output
        run: |
          python clean_jobs_cplus.py

      - name: Validate Output CSV
        run: |
          python validate_output.py

      - name: Commit & Push CSV
        if: success()
        env:
          PUSH_TOKEN: ${{ secrets.CI_JOB_SCRAPER_GITHUB_ACTION_TOKEN }}
        run: |
          git config --global user.email "243287379+hardikkaushik-jpg@users.noreply.github.com"
          git config --global user.name "hardikkaushik-jpg"
          git add jobs_cleaned_final_enriched.csv jobs_final_hard.csv || true
          git commit -m "Automated enterprise scrape (C+)" || echo "No changes to commit"
          git push "https://x-access-token:${PUSH_TOKEN}@github.com/${{ github.repository }}" main --force
