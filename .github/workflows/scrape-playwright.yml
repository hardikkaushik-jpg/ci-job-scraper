name: Scrape and Push Jobs (Enterprise C+ Pipeline)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"  # daily at 06:00 UTC

jobs:
  scrape_and_clean:
    runs-on: ubuntu-latest
    steps:
      # Checkout code
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      # Setup Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install chromium

      # Run scraper (C+ version)
      - name: Run Enterprise Scraper
        run: |
          python jobs_smart_cplus.py

      # Run cleaner (C+ version)
      - name: Clean & Enrich Output
        run: |
          python clean_jobs_cplus.py

      # Validate output accuracy/quality
      - name: Validate Output CSV
        run: |
          python validate_output.py

      # Commit & push ONLY IF validation succeeded
      - name: Commit & Push CSV (Secure Push)
        if: success()    # Only push when validator passes
        env:
          PUSH_TOKEN: ${{ secrets.CI_JOB_SCRAPER_GITHUB_ACTION_TOKEN }}
        run: |
          git config --global user.email "243287379+hardikkaushik-jpg@users.noreply.github.com"
          git config --global user.name "hardikkaushik-jpg"

          # Add ONLY the cleaned CSV
          git add jobs_cleaned_final_enriched.csv || true

          git commit -m "Automated enterprise scrape (C+ version)" || echo "No changes to commit"

          # Force push to main using token
          git push "https://x-access-token:${PUSH_TOKEN}@github.com/${{ github.repository }}" main --force
