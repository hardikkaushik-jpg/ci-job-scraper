name: Job Scraper

on:
  schedule:
    # runs every day at 8am UTC; adjust if you want
    - cron: '0 8 * * *'
  workflow_dispatch: # allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout repo
    - name: Checkout repo
      uses: actions/checkout@v3

    # 2. Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    # 3. Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # 4. Run your scraper
    - name: Run job scraper
      run: python jobs_scraper.py

    # 5. Configure Git
    - name: Configure Git
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"

    # 6. Commit and push jobs.csv if there are changes
    - name: Commit and push changes
      uses: ad-m/github-push-action@v0.6.0
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: main  # adjust if your default branch is not main
        commit_message: "Update jobs.csv from scraper"
